参考：

- [自监督对抗哈希SSAH：当前最佳的跨模态检索框架](https://www.jiqizhixin.com/articles/CVPR2018-Self-Supervised-Adversarial-Hashing-Networks)
- https://arxiv.org/pdf/1804.01223.pdf

----------


![这里写图片描述](http://img.blog.csdn.net/20180420164128660?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
作者使用**两个对抗网络**来联合学习高维特征和它们在不同模态下的对应哈希编码。同时，一方面使用对抗学习来有监督地最大化不同模态之间语义关联和特征分布一致性；另一方面无缝添加一个自监督的语义网络，来发现多标签标注中的语义信息。该模型的主要亮点如下：

- 本文提出了一个新型的用于跨模态检索的自监督对抗哈希模型。据作者介绍，这是第一批尝试将对抗学习应用到跨模态哈希问题的工作之一。

- 本文将自监督语义学习和对抗学习结合，以尽可能保留不同模态之间的语义相关性和表征一致性。使用这种方式可以有效地打破模态鸿沟。

- 基于三个评测数据集的大规模实验结果，表明本文提出的 SSAH 明显优于当前最好的基于传统方法和深度学习方法的跨模态哈希算法。

# 本文提出的 SSAH
这个方法主要由三个部分组成，包括了一个自监督语义生成网络（LabNet）和两个分别用于图像和文本的对抗网络（ImgNet 和 TexNet）。

具体来说，LabNet 的目标设定使它可以从**多标签标注**中学习到语义特征。然后，它可以被视为用于监督两个阶段的模态特征学习的公共语义空间。第一个阶段，在公共的语义空间中将来自不同生成网络的模态特定的特征联系起来。考虑到深度神经网路的每个输出层都包含了语义信息，在公共的语义空间中将模态特定的特征联系起来，可以帮助提高模态之间的语义相关性。第二个阶段，把语义特征和模态特定的特征同时馈送进两个判别网络。因此，在相同语义特征的监督下，两个模态的特征分布最终会趋于一致。

具体来说，LabNet的目标是以允许其从多标签注释中学习语义特征的方式进行构建的。它可以被认为是一个共同的语义空间，在这个空间中监督两个阶段的情态特征学习。在第一阶段，来自不同发生器网络的特定于模态的特征在共同的语义空间中彼此关联。由于深层神经网络中的每个输出层都包含语义信息，因此将共同语义空间中特定于模态的特征关联起来有助于提升模态之间的语义相关性。在第二阶段，语义特征和特定于模态的特征同时馈入两个鉴别器网络。结果，两种模式的特征分布趋于在相同语义特征的监督下变得一致。在本节中，我们将详细介绍我们的SSAH方法，包括模型制定和方法背后的方法学习算法。

## 3.1 公式

$O=${$o_i$}$^n_{i=1}$

- n个实例的跨模态数据集
- $o_i=  (v_i,t_i,l_i)$
- $v_i∈R^{1×d_v}$  第i个实例的原始图像特征
- $t_i∈R^{1×d_t}$  第i个实例的文本特征
- $l_i= [l_{i1},...,l_{ic}]$ 将多标签注释分配给$o_i$
- $c$ 类别数
- 如果$o_i$属于第j个类，则$l_{ij}=1$,否则$l_{ij}=0$
- 图像特征矩阵被定义为$V$
- 文本特征矩阵定义为$T$
- 标签矩阵为$L$

成对多标签相似度矩阵$S$用于描述两个实例中的每一个之间语义相似性

- $S_{ij}=1$ 意为$o_i$ 与$o_j$相似，否则为0

在多标签设置中，两个实例（$o_i$和$o_j$）由多个标签注释

- $S_{ij}=1$   ，$o_i$和$o_j$至少分享一个标签，否则为0

跨模态哈希的目标是为这两种模式学习统一的哈希码：

$B^{v,t}∈${−1,1}$^K$

- $K$ 二进制编码的长度

使用汉明距离，计算两个编码的相似性

- $dis_H(b_i,b_j)$ 汉明距离 ，
- 内积 $〈b_i,b_j〉$  ，
- 使用$dis_H(b_i,b_j)  =\frac{1} {2}(K− 〈b_i,b_j〉)$  ，我们可以使用内积来量化两个二进制代码的相似度。

给定S，条件B下的S的概率可以表示为：

<center>$p(S_{ij}|B)=\left\{\begin{matrix}\delta(\Psi _{ij}),  & S_{ij}=1 & \\ 1-\delta(\Psi _{ij}), & S_{ij}=0 & \end{matrix}\right.   (1)$ 

- $\delta(\Psi _{ij})=\frac{1}{1+e^{-\Psi _{ij}}}$
- $\Psi _{ij}=\frac{1}{2}<b_i,b_j>$

- 具有较大内积的两个实例应该很可能具有相似性。

- 量化海明空间中的二进制码之间的相似性的问题因此可以转化为编码的原始特征的内积的计算。

在这里，我们构建了一对对抗网络（ImgNet和TxtNet）来学习图像和文本模式的单独哈希函数（$H^{v,t}=f^{v,t}(v,t;θ^{v,t})$）。同时，我们构建了一个端到端的自我监督语义网络（LabNet），以便在学习语义特征的散列函数的同时，将图像和文本形态之间的语义相关性建模到共同的语义空间中（$H^l=f^l(l;θ^l)$）

- $f^{v,t,l}$ —— 哈希函数
- $θ^{v,t,l}$  ——要学习的网络参数。

通过$H^{v,t,l}$学习 ，二进制编码$B^{v,t,l}$可以通过sign函数按以下方式生成
<center>$B^{v,t,l}=sign(H^{v,t,l})∈ ${$−1,1$}$^K $  ,            (2)


- $F^{v,t,l} \in \mathbb{R}^{s\times n}$ 表示图像，文本和标签的共同语义空间中的语义特征
- $F^{v,t,l}$对应于深层神经网络的某些输出层（ImgNet，TxtNet和 LabNet）

## 3.2 自我监督的语义生成
以微软的COCO数据集为例，有一个实例用多个标签进行了注释，例如“人”，“棒球棒”和“棒球手套”。在这种情况下，最自然的想法是，可以将多标签注释作为一种有利的方式，以便在更细粒度的层次上弥合模态之间的语义相关性。我们设计了<font color=##dd00>一个端到端的全连接深层神经网络，命名为LabNet</font>，为不同模式之间的语义相关性建模,以模拟不同形式之间的语义相关性。给定一个实例的多标签向量，LabNet会逐层提取抽象的语义特征; 通过这些我们可以监督ImgNet和TxtNet中的特征学习过程。由于三元组（$v_i$,$t_i$,$l_i$）用于描述相同的第i个实例,我们认为$l_i$作为$v_i$和$t_i$自我监督的语义信息。在LabNet中，通过非线性变换将语义特征投影到相应的哈希码中。我们的意图是语义特征和它们相应的哈希码之间的相似关系保存得很好; 这是不同形式之间有效关联背后的基本前提。因此，对LabNet来说，最终目标可以表述如下：

![这里写图片描述](http://img.blog.csdn.net/20180420201504038?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

- $∆^l_{ij}= \frac {1}{2}(F^l_{∗i})^T(F^l_{∗j})$
- $\Gamma_{ij}^{l}=\frac{1}{2}(H_{*i}^{l})^{T}(H_{*j}^{l}) $
- $H^l$是预测的哈希码
-  $\hat{L^l}$ 预测标签
- 3式中，$\jmath_{1}$ 和$\jmath_{2}$ 两个负对数似然函数
- $\jmath_{1}$ 用于保持语义特征之间的相似性
- $\jmath_{2}$用于保留类似标签信息具有相似散列码的情况。
- $\jmath_{3}$是学习哈希码的二值化的近似损失，
- $\jmath_{4}$原始标签和预测标签的分类损失

## 3.3 特征学习
如上所述，属于多模态实例的不同模态在语义上是相关的。为了保持这种语义相关性，我们监督LabNet指导下的两种模式的特征学习过程，包括监督语义特征和学习的二进制编码。为了解决图像模态问题，我们设计了一个名为<font color=FF00FF>ImgNet</font>的端到端特征学习网络，该网络可以将图像投影到哈希编码中。通过使用语义网络监督图像特征学习，我们可以在ImgNet和语义网络之间保持相同的语义相关性。这是在ImgNet中使用时的语义网络的自我监督角色。同样，在考虑文本形式时，我们使用语义网络以同样的方式监督TxtNet的特征学习过程。因此，$v$和$t$中不同形式的自监督特征学习的目标函数可写为：

![这里写图片描述](http://img.blog.csdn.net/20180420203436318?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

- $\Delta_{i,j}^{v,t}=\frac{1} {2}(F_{*i}^{l})^{T}(F_{*j}^{v,t})$
- $\Gamma_{i,j}^{v,t}=\frac{1}{2}(H_{*i}^{l})^{T}(H_{*j}^{v,t})$ 
- $H^{v,t}$ 预测的哈希码
-  $\hat{L^{v,t}}$ 图像和文本的预测标签
- 超参数$ \alpha ,\gamma ,\eta ,\beta $
- $\jmath_{1}$ 和$\jmath_{2}$ 两个负对数似然函数
- $\jmath_{3}$ 和$\jmath_{4}$是以类似于LabNet中使用的方式定义的近似损失和分类损失

应该指出的是，虽然（3）和（4）式在结构上类似，它们具有不同的含义。因此，我们使用监督信息$F_{*i}^{l}$ 和$H_{*i}^{l}$（从语义网络中学习）指导ImgNet和TxtNet的学习过程。相关性可以使用语义网络来建立。 因此，可以缓解形态差距。

与图像形态相比，文本形式中的实例（通常由bag-of-word（BoW）向量表示）容易导致稀疏性。因此，当发现学习散列码所需的有价值信息时，BoW是不适合的。为了解决这个问题，我们设计了一个多尺度融合模型，它由多个平均池化层和一个1×1卷积层组成。使用多个平均池化层为文本数据提取多个比例特征，然后使用1×1卷积图层融合多个特征。通过这个过程，不同单词之间的关联也可以被捕获，这在为文本形式构建语义相关性时是有用的。更详细的参数信息在章节3.6中给出。

## 3.4  Adversarial Learning
在LabNet的监督下，语义相关性可以在不同的模式下保存。 但是，不同的模式通常是不一致分布的，如果我们想要生成统一的哈希码，这是不利的。 为了弥补这种形式差距并使得更准确的检索，我们以对抗学习方式研究了不同形式的分发协议。我们已经为图像和文本模式建立了两个辨别器，以发现它们的分布差异。 对于图像（文本）鉴别器，输入是图像（文本）形态特征和通过生成的语义特征LabNet，输出是一个单一的值，可以是“0”或“1”。具体而言，我们将从标签生成的语义特征的模态标签定义为“1”，并将ImgNet（TxtNet）生成的图像（文本）语义模态特征的模态标签定义为“0”。

![这里写图片描述](https://image.jiqizhixin.com/uploads/editor/c810afa4-ee7b-4cc1-9922-bf136358c55c/1523599419373.jpg)

我们输入$F^v$,$F^l$到图像设计的鉴别器,$F^t$,$F^l$进入另一个专为文本设计的鉴别器。为了制定这种结构，$Y=${y_i}$_{i=1}^{3\times n}$,

- $y_i∈${$0,1$}表示分配给共享公共语义特征的模态标签
空间
- $Y^l=${y$_i^l$}$_{i=1}^{n}$ ，$y_i^{l}=0$ 表示标签的形式标签
- $Y^{v,t}=${y$_i^{v,t}$}$_{i=1}^{n}$ ，$y_i^{v,t}=0$ 表示图像和文本的模态标签

在训练我们的模型时，这两个鉴别者充当两个对手。 因此，目标函数可以写成如下：
![这里写图片描述](http://img.blog.csdn.net/20180420212027814?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

- $x_i^{v,t,l}$是共同语义空间中的语义特征，
- $y_i^{v,t,l}$是形式标签
- $2 \times n$ 表示送入每个鉴别器的实例的数量。

（5）的结果是鉴别器充当两个二元分类器，将输入语义特征分类到类“1”和类“0”。

## 3.5 优化
注意到可以使用我们的SSAH生成三种哈希码：$B^{v,t,l}=sign(H^{v,t,l})$。在训练过程，我们使用$B=sign(H^v+H^t+H^l)$训练我们的模型来为语义相似的实例生成相似的二进制代码。如上所述，总体目标函数可写成如下：
![这里写图片描述](http://img.blog.csdn.net/20180420212802943?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

如果我们把它们放在一起，我们可以得到：
![这里写图片描述](http://img.blog.csdn.net/20180420212848913?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
由于参数B的离散性和由极大极小损失引起的消失梯度问题，（7）的优化是棘手的。因此，我们通过迭代优化来优化目标（7）。首先，我们优化$\iota^l $在$\theta^l$,$B^l$和$\hat{L}^l$通过探索标签信息。然后我们优化$\iota^v$ 在$\theta^v$,$B^v$，固定$\theta^l$,$B^l$。类似的我们固定$\theta^l$,$B^l$学习$\theta^t$,$B^t$通过优化$\iota^t$ 。

在这个过程中，两种模态特征是在自我监督下学习的学习方式。最后，我们优化$\iota_{adv}^{v,t}$在$\theta^{v,t}$通过固定$\theta^{v,t,l}$。值得注意的是，所有的网络参数都是通过利用随机梯度下降（SGD）和反向传播（BP）算法来学习的，这在现有的深度学习方法中被广泛采用。 算法1详细列出了整个学习算法。

对于样本外扩展：所提议的框架可以应用于跨模式。 事实上，它不限于两种模式; 相反，它可以很容易地适用于解决两种以上情况下的问题。 可以通过将原始特征提供给我们的模型直接获得可能来自不同模态，图像或文本的未见数据点的哈希编码:
<center>$b_q^{v,t,l}=sign(f^{v,t,l}(b_q;\theta^{v,t,l}))              ,       (8)$

而且，通过将标签信息提供给LabNet，我们可以获得标签信息的哈希码，然后可以同时从图像和文本中检索相关结果。


## 3.6 实施细节
**自我监督的语义网络**：我们用四层前馈神经网络构建了LabNet，它们都是用于将标签投影到哈希码中（L→4096→512→N）。输出层N的节点与哈希码的长度K和不同数据集的总类标签c有关，$N=K+c$

**图像生成网络**: 我们基于CNN-F [5]神经网络构建了ImgNet。为了将CNN应用于我们的SSAH模型，我们保留了前七层（与CNN-F中的相同）。在此之后，中间层fc8（具有512个节点）和最终输出层（具有N个节点）被构筑。 另外，我们还使用vgg19 [32]网络评估了我们的方法; 在这里，我们用vgg19网络取代了CNN-F网络其余的保持不变。

**文本生成网络**: 我们使用三层前馈神经网络和多尺度（MS）建立TxtNet融合模型(T→MS→4096→512→N).MS由五层池化层组成(1×1,  2×2,  3×3,  5×5,and 10×10)。

**对抗网络：**我们使用三层前馈神经网络构建鉴别器网络$(F^{v,t,l}→4096→4096→1)$.

关于SSAH中使用的激活函数：sigmoid激活用于输出预测标签; tanh激活用于输出散列码; 其余的层都是由relu函数统一激活的。 另外，SSAH通过TensorFlow实现，并在具有两个NVIDIA TITAN X GPU的服务器上运行。

# 流程图分析
![这里写图片描述](http://img.blog.csdn.net/20180421103438831?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180421171905579?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
